
# CUDA_VISIBLE_DEVICES=0,1 python3 -m sglang.launch_server --model-path /data/sdb2/wyh/models/Qwen2.5-32B-Instruct --attention-backend triton --sampling-backend pytorch --disable-radix-cache --disable-regex-jump-forward --disable-cuda-graph --disable-cuda-graph-padding --disable-disk-cache --disable-custom-all-reduce --disable-mla --random-seed 7 --host 0.0.0.0 --port 30002 --mem-fraction-static 0.8 --max-running-request 1 --tp 2

CUDA_VISIBLE_DEVICES=1 python3 -m sglang.launch_server --model-path /data/sdb2/wyh/models/Mistral-7B-Instruct-v0.3 --attention-backend triton --sampling-backend pytorch --random-seed 7 --host 0.0.0.0 --port 30001 --mem-fraction-static 0.8 --max-running-request 1
# CUDA_VISIBLE_DEVICES=1 python3 -m sglang.launch_server --model-path /data/sdb2/lzy/LLM/Qwen2.5-7B-Instruct --attention-backend triton --sampling-backend pytorch --random-seed 7 --host 0.0.0.0 --port 30001 --mem-fraction-static 0.8 --max-running-request 1
# CUDA_VISIBLE_DEVICES=2 python3 -m sglang.launch_server --model-path /data/sdb2/wyh/models/Mistral-7B-Instruct-v0.3 --attention-backend triton --sampling-backend pytorch --disable-radix-cache --disable-regex-jump-forward --disable-cuda-graph --disable-cuda-graph-padding --disable-disk-cache --disable-custom-all-reduce --disable-mla --random-seed 7 --host 0.0.0.0 --port 30003 --mem-fraction-static 0.8 --max-running-request 1
# CUDA_VISIBLE_DEVICES=0 python3 -m sglang.launch_server --model-path /data/sdb2/lzy/LLM/Meta-Llama-3-8B-Instruct --attention-backend triton --sampling-backend pytorch --disable-radix-cache --disable-regex-jump-forward --disable-cuda-graph --disable-cuda-graph-padding --disable-disk-cache --disable-custom-all-reduce --disable-mla --random-seed 7 --host 0.0.0.0 --port 30002 --mem-fraction-static 0.8 --max-running-request 1
# CUDA_VISIBLE_DEVICES=1 python3 -m sglang.launch_server --model-path /data/sdb2/wyh/models/Qwen2.5-14B-Instruct --attention-backend triton --sampling-backend pytorch --disable-radix-cache --disable-regex-jump-forward --disable-cuda-graph --disable-cuda-graph-padding --disable-disk-cache --disable-custom-all-reduce --disable-mla --random-seed 7 --host 0.0.0.0 --port 30001 --mem-fraction-static 0.8 --max-running-request 1
# CUDA_VISIBLE_DEVICES=1 python3 -m sglang.launch_server --model-path /data/sdb2/wyh/models/DeepSeek-R1-Distill-Llama-8B --attention-backend triton --sampling-backend pytorch --disable-radix-cache --disable-regex-jump-forward --disable-cuda-graph --disable-cuda-graph-padding --disable-disk-cache --disable-custom-all-reduce --disable-mla --random-seed 7 --host 0.0.0.0 --port 30001 --mem-fraction-static 0.8 --max-running-request 1

# CUDA_VISIBLE_DEVICES=0 python3 -m sglang.launch_server --model-path /data/sdb2/lzy/LLM/Llama-3.2-1B-Instruct --attention-backend triton --sampling-backend pytorch --disable-radix-cache --disable-regex-jump-forward --disable-cuda-graph --disable-cuda-graph-padding --disable-disk-cache --disable-custom-all-reduce --disable-mla --random-seed 7 --host 0.0.0.0 --port 30002 --mem-fraction-static 0.8 --max-running-request 1
